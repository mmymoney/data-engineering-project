{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Adj Close</th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1985-01-29</td>\n      <td>1277.719971</td>\n      <td>1295.489990</td>\n      <td>1266.890015</td>\n      <td>1292.619995</td>\n      <td>1292.619995</td>\n      <td>13560000</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1985-01-30</td>\n      <td>1297.369995</td>\n      <td>1305.099976</td>\n      <td>1278.930054</td>\n      <td>1287.880005</td>\n      <td>1287.880005</td>\n      <td>16820000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1985-01-31</td>\n      <td>1283.239990</td>\n      <td>1293.400024</td>\n      <td>1272.640015</td>\n      <td>1286.770020</td>\n      <td>1286.770020</td>\n      <td>14070000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1985-02-01</td>\n      <td>1276.939941</td>\n      <td>1286.109985</td>\n      <td>1269.770020</td>\n      <td>1277.719971</td>\n      <td>1277.719971</td>\n      <td>10980000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1985-02-04</td>\n      <td>1272.079956</td>\n      <td>1294.939941</td>\n      <td>1268.989990</td>\n      <td>1290.079956</td>\n      <td>1290.079956</td>\n      <td>11630000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "         Date         Open         High          Low        Close  \\\n0  1985-01-29  1277.719971  1295.489990  1266.890015  1292.619995   \n1  1985-01-30  1297.369995  1305.099976  1278.930054  1287.880005   \n2  1985-01-31  1283.239990  1293.400024  1272.640015  1286.770020   \n3  1985-02-01  1276.939941  1286.109985  1269.770020  1277.719971   \n4  1985-02-04  1272.079956  1294.939941  1268.989990  1290.079956   \n\n     Adj Close    Volume  \n0  1292.619995  13560000  \n1  1287.880005  16820000  \n2  1286.770020  14070000  \n3  1277.719971  10980000  \n4  1290.079956  11630000  "
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#store djia market data from CSV as a dataframe\n",
    "file_dji = './Resources/DJI.csv'\n",
    "dji_df = pd.read_csv(file_dji)\n",
    "dji_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "One or more keys not available for deletion (potential re-run)\n"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Close_DJIA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1985-01-29</td>\n      <td>1292.619995</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1985-01-30</td>\n      <td>1287.880005</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1985-01-31</td>\n      <td>1286.770020</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1985-02-01</td>\n      <td>1277.719971</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1985-02-04</td>\n      <td>1290.079956</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "         Date   Close_DJIA\n0  1985-01-29  1292.619995\n1  1985-01-30  1287.880005\n2  1985-01-31  1286.770020\n3  1985-02-01  1277.719971\n4  1985-02-04  1290.079956"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform data as-needed\n",
    "\n",
    "#exception handle for re-runs\n",
    "try:\n",
    "    del dji_df['Open']\n",
    "    del dji_df['High']\n",
    "    del dji_df['Low']\n",
    "    del dji_df['Adj Close']\n",
    "    del dji_df['Volume']\n",
    "except KeyError:\n",
    "    print('One or more keys not available for deletion (potential re-run)')\n",
    "    pass\n",
    "\n",
    "dji_df = dji_df.rename(columns={'Close':\"Close_DJIA\"})\n",
    "dji_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DATE</th>\n      <th>NASDAQCOM</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>2000-01-03</td>\n      <td>4131.15</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2000-01-04</td>\n      <td>3901.69</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2000-01-05</td>\n      <td>3877.54</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2000-01-06</td>\n      <td>3727.13</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2000-01-07</td>\n      <td>3882.62</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "         DATE NASDAQCOM\n0  2000-01-03   4131.15\n1  2000-01-04   3901.69\n2  2000-01-05   3877.54\n3  2000-01-06   3727.13\n4  2000-01-07   3882.62"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#store nasdaq market data from CSV as a dataframe\n",
    "file_nasdaq = './Resources/NASDAQCOM.csv'\n",
    "nasdaq_df = pd.read_csv(file_nasdaq)\n",
    "nasdaq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DATE</th>\n      <th>Close_NASDAQCOMPOSITE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>2000-01-03</td>\n      <td>4131.15</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2000-01-04</td>\n      <td>3901.69</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2000-01-05</td>\n      <td>3877.54</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2000-01-06</td>\n      <td>3727.13</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2000-01-07</td>\n      <td>3882.62</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>5256</td>\n      <td>2020-02-25</td>\n      <td>8965.613</td>\n    </tr>\n    <tr>\n      <td>5257</td>\n      <td>2020-02-26</td>\n      <td>8980.773</td>\n    </tr>\n    <tr>\n      <td>5258</td>\n      <td>2020-02-27</td>\n      <td>8566.48</td>\n    </tr>\n    <tr>\n      <td>5259</td>\n      <td>2020-02-28</td>\n      <td>8567.367</td>\n    </tr>\n    <tr>\n      <td>5260</td>\n      <td>2020-03-02</td>\n      <td>8952.165039</td>\n    </tr>\n  </tbody>\n</table>\n<p>5261 rows Ã— 2 columns</p>\n</div>",
      "text/plain": "            DATE Close_NASDAQCOMPOSITE\n0     2000-01-03               4131.15\n1     2000-01-04               3901.69\n2     2000-01-05               3877.54\n3     2000-01-06               3727.13\n4     2000-01-07               3882.62\n...          ...                   ...\n5256  2020-02-25              8965.613\n5257  2020-02-26              8980.773\n5258  2020-02-27               8566.48\n5259  2020-02-28              8567.367\n5260  2020-03-02           8952.165039\n\n[5261 rows x 2 columns]"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform data as-needed\n",
    "nasdaq_df = nasdaq_df.rename(columns={'NASDAQCOM': 'Close_NASDAQCOMPOSITE'})\n",
    "nasdaq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Country</th>\n      <th>Cumulative number of case(s)</th>\n      <th>Number of deaths</th>\n      <th>Number recovered</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>2003-03-17</td>\n      <td>Germany</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2003-03-17</td>\n      <td>Canada</td>\n      <td>8</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2003-03-17</td>\n      <td>Singapore</td>\n      <td>20</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2003-03-17</td>\n      <td>Hong Kong SAR, China</td>\n      <td>95</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2003-03-17</td>\n      <td>Switzerland</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "         Date               Country  Cumulative number of case(s)  \\\n0  2003-03-17               Germany                             1   \n1  2003-03-17                Canada                             8   \n2  2003-03-17             Singapore                            20   \n3  2003-03-17  Hong Kong SAR, China                            95   \n4  2003-03-17           Switzerland                             2   \n\n   Number of deaths  Number recovered  \n0                 0                 0  \n1                 2                 0  \n2                 0                 0  \n3                 1                 0  \n4                 0                 0  "
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#store SARS data from CSV as a dataframe\n",
    "file_sars = './Resources/sars_2003_complete_dataset_clean.csv'\n",
    "sars_df = pd.read_csv(file_sars)\n",
    "sars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform data as-needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xa0 in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xa0 in position 0: invalid start byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-f8f8acd4224d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#store H1N1 data from CSV as a dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile_h1n1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./Resources/Pandemic (H1N1) 2009.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mh1n1_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_h1n1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mh1n1_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2057\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xa0 in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "#store H1N1 data from CSV as a dataframe\n",
    "file_h1n1 = './Resources/Pandemic (H1N1) 2009.csv'\n",
    "h1n1_df = pd.read_csv(file_h1n1)\n",
    "h1n1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform data as-needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store Ebola data from CSV as a dataframe\n",
    "file_ebola = './Resources/ebola_2014_2016_clean.csv'\n",
    "ebola_df = pd.read_csv(file_ebola)\n",
    "ebola_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform data as-needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store Covid-19 data from CSV as a dataframe\n",
    "file_covid = './Resources/covid_19_clean_complete.csv'\n",
    "covid_df = pd.read_csv(file_covid)\n",
    "covid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform data as-needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to AWS cloud database\n",
    "connection_string = ''\n",
    "engine = create_engine(f'postgresql://{connection_string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check tables\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pandas to load market data df into database\n",
    "<dataframe>.to_sql(name = '<name>', con = engine, if_exists = 'replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pandas to load SARS data df into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pandas to load H1N1 data df into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pandas to load Ebola data df into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pandas to load Covid-19 data df into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query tables to validate load\n",
    "<df>.read_sql_query('<query>', con = engine).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}